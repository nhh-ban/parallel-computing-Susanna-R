# The map-functions will generally give an error if they receive an error when
# applied to any of the items it is applied to. In the example below we get an
# error due to a character-entry in the list. This might seem frustrating,
# but it forces you to actively make a choice of how you want to deal with the errors.
x <- list(1, 10, "a")
y <- x |> map(log)
# 7.1.1 Iterating over columns
library(purrr)
library(tidyverse)
df <-
tibble(
a = rnorm(10),
b = rnorm(10),
c = rnorm(10),
d = rnorm(10),
e = rnorm(10),
)
median(df$a)
median(df$b)
median(df$c)
median(df$d)
median(df$e)
col_summary <- function(df, fun) {
out <- vector("double", length(df))
for (i in seq_along(df)) {
out[i] <- fun(df[[i]])
}
out
}
# call function with different summary functions
col_summary(df, mean)
col_summary(df, median)
col_summary(df, sd)
# The example above could be solved with the function map.
map(df, mean)
df |>
map(mean, trim=.1) |>
bind_cols()
df |>
map(
{
\(x) mean(x) / sd(x)
}
) |>
bind_cols()
mtcars |>
split( ~ cyl) |>
map({
\(x)lm(mpg ~ wt, data = x)
}) |>
map(summary) |>
map({
\(x) x$r.squared
}) |>
bind_cols()
mtcars |>
split(~cyl) |>
map({\(x)lm(mpg~wt, data=x) }) |>
map(summary) |>
map("r.squared")|>
bind_cols()
# The map-functions will generally give an error if they receive an error when
# applied to any of the items it is applied to. In the example below we get an
# error due to a character-entry in the list. This might seem frustrating,
# but it forces you to actively make a choice of how you want to deal with the errors.
x <- list(1, 10, "a")
y <- x |> map(log)
# We can wrap the function call in the function safely
y <- x |> map(safely(log))
y |>
map("error") |>
map(is_null)
# possibly is a different option. This function will insert a default value
# (NA_real below) in case the function call fails.
x |> map(possibility(log, NA_real_))
# possibly is a different option. This function will insert a default value
# (NA_real below) in case the function call fails.
x |> map(possibly(log, NA_real_))
# If we want to iterate over two lists (of the same length) simultaneously,
# we can do so by using map2:
mu <- list(-10000, 0, 10000)
sigma <- list(1, 5, 10)
map2(mu,sigma,rnorm,n=5)
# We can also iterate over more than two lists simultaneously.
# The lists then need to be combined in a single list,
# and the names of each list must match the names of the arguments in the
# function we want to apply.
mu <- list(-10000, 0, 100)
sigma <- list(1, 5, 10)
n <- list(1, 10, 25)
list(mean = mu,
sd = sigma,
n = n) |>
pmap(rnorm)
# 7.2.1 Getting some data ------
# Let’s apply the purrr-functions on a more realistic data set.
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
# 7.2.1 Getting some data ------
# Let’s apply the purrr-functions on a more realistic data set.
install.packages(anytime)
# 7.2.1 Getting some data ------
# Let’s apply the purrr-functions on a more realistic data set.
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
install.packages(DescTools)
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
# The URL we will use is stored below:
url <- "https://www.vegvesen.no/trafikkdata/api/"
View(GQL)
qry <-
'
{
trafficRegistrationPoints {
id
name
latestData {
volumeByDay
}
location {
coordinates {
latLon {
lat
lon
}
}
}
}
}
'
# Allright - let's try submitting the query:
stations <-GQL(qry)
View(stations)
# list
length(stations)
length(stations[[1]])
# 7.2.2 Transforming list-columns -----
# Now we want to add station id, station name, date of latest recording and coordinate.
# We will name the columns id, name, lasestdata, lat and lon.
stations[[1]][[1]]
stations[[1]][[1]] |>
as_tibble()
#
stations[[1]] |>
map(as_tibble) |>
list_rbind()
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
head(1) |>
select(latestData) |>
pull()
View(stations)
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, 1))
unlist_safe <-
function(x){
x <- unlist(x)
if(is.null(x)){
return(NA_character_)
}else{
return(x)
}
}
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, unlist_safe))
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
mutate(
latestData = map_chr(latestData,1, .default=NA_character_)
)
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, 1, .default=NA_character_)) |>
mutate(latestData = as.Date(latestData))
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, 1, .default = NA_character_)) |>
mutate(latestData = as_datetime(latestData, tz = "Europe/Berlin"))
# Lets take on the final location variable.
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, 1, .default = ""))  |>
mutate(latestData = as_datetime(latestData, tz = "Europe/Berlin"))  |>
mutate(location = map(location, unlist)) |>
mutate(
lat = map_dbl(location, "latLon.lat"),
lon = map_dbl(location, "latLon.lon")
) %>%
select(-location)
knitr::opts_chunk$set(echo = TRUE)
install.packages("GPArotation", repos="https://cran.rstudio.com/")
library("GPArotation")
myvars<-names(data1) %in% c("Com1", "Com2",  "Com3", "Com4", "Toldev1", "RepSup4", "RepRest3", "RepRest4")
knitr::opts_chunk$set(echo = TRUE)
install.packages("GPArotation", repos="https://cran.rstudio.com/")
install.packages("GPArotation", repos = "https://cran.rstudio.com/")
library("GPArotation")
library(foreign)
library(psych)
data1<-read.spss("Meas2018.sav",  use.value.labels=FALSE, to.data.frame = TRUE)
headTail(data1) #shows the first and last cases, useful to see if the data is imported correctly
describe(data1)
library(psych)
lowerCor(data1) #Shows the lower triangle + the diagonal
```{r visualization Meas2018, fig.height=10, fig.width=14}
pairs.panels(data1)
corPlot(data1, number=TRUE, upper=TRUE, diag=TRUE, main="Red meat study")
library(psych)
Reldata1<-subset(data1, select=c(Com1,Com2,Com3,Com4))#select variables measuring commitment
a1<-alpha(Reldata1)
print(a1)
Reldata2<-subset(data1, select=c(Toldev1,Toldev2, Toldev3, Toldev4))#select variables measuring tolerance for deviations
a2<-alpha(Reldata2)
print(a2)
Reldata3<-subset(data1, select=c(RepSup1,RepSup2, RepSup3, RepSup4))#select variables measuring supplier reputation
a3<-alpha(Reldata3)
print(a3)
Reldata4<-subset(data1, select=c(RepRest1,RepRest2, RepRest3, RepRest4))#select variables measuring restaurant reputation
a4<-alpha(Reldata4)
print(a4)
CF4<-fa(data1, nfactors=4, fm="ml", rotate="oblimin", ) #nfactors refers to # of factors, fm="ml" refers to extraction method (maximum likelihood), and rotate refers to type of rotation (oblimin is an oblique rotation)
CF4
fa.diagram(CF4) # plot the factor solution
CF33<-fa(data1, nfactors=3, fm="ml", rotate="oblimin", ) #nfactors refers to # of factors, fm="ml" refers to extraction method (maximum likelihood), and rotate refers to type of rotation (oblimin is an oblique rotation)
CF33
fa.diagram(CF33) # plot the factor solution
CF2<-fa(data1, nfactors=2, fm="ml", rotate="oblimin", ) #nfactors refers to # of factors, fm="ml" refers to extraction method (maximum likelihood), and rotate refers to type of rotation (oblimin is an oblique rotation)
CF2
fa.diagram(CF2) # plot the factor solution
myvars<-names(data1) %in% c("Com1", "Com2",  "Com3", "Com4", "Toldev1", "RepSup4", "RepRest3", "RepRest4")
newdata2<-data1[!myvars] #remove items
CF3R<-fa(newdata2, nfactors=3, fm="ml", rotate="oblimin", ) #in this case you have removed many items (for instance all commitment items) and perhaps you expect fewer factors (in this case 3)
CF3R
fa.diagram(CF3R)
CF3R
myvars<-names(data1) %in% c("Com1", "Com2",  "Com3", "Com4", "Toldev1", "Toldev2", "RepSup4", "RepRest3", "RepRest4")
newdata2<-data1[!myvars] #remove items
CF3R<-fa(newdata2, nfactors=3, fm="ml", rotate="oblimin", ) #in this case you have removed many items (for instance all commitment items) and perhaps you expect fewer factors (in this case 3)
CF3R
myvars<-names(data1) %in% c("Com1", "Com2",  "Com3", "Com4", "Toldev1", "Toldev2", "RepRest3", "RepRest4")
newdata2<-data1[!myvars] #remove items
CF3R<-fa(newdata2, nfactors=3, fm="ml", rotate="oblimin", ) #in this case you have removed many items (for instance all commitment items) and perhaps you expect fewer factors (in this case 3)
CF3R
CF4
myvars<-names(data1) %in% c("Com1", "Com2",  "Com3", "Com4", "Toldev1", "Toldev2", "RepSup4", "RepRest3", "RepRest4")
newdata2<-data1[!myvars] #remove items
CF3R<-fa(newdata2, nfactors=3, fm="ml", rotate="oblimin", ) #in this case you have removed many items (for instance all commitment items) and perhaps you expect fewer factors (in this case 3)
CF3R
myvars<-names(data1) %in% c("Com1", "Com2",  "Com3", "Com4", "Toldev1", "Toldev2", "RepSup4", "RepRest3", "RepRest4")
newdata2<-data1[!myvars] #remove items
CF3R<-fa(newdata2, nfactors=3, fm="ml", rotate="oblimin", ) #in this case you have removed many items (for instance all commitment items) and perhaps you expect fewer factors (in this case 3)
CF3R
fa.diagram(CF3R)
CF3R
# 9.1 A time consuming problem
library(tidyverse)
setwd("/Users/susannaroald/Documents/BAN400/Lecture 9")
load("parallel_data.Rdata")
load("parallel_data.Rdata")
View(df)
View(df)
sales_price_mnok <- 1
car_cost_mnok <- .95
df %>%
head() %>%
knitr::kable()
calcProfits <-
function(df,
sales_price_mnok,
car_cost_mnok,
lead_days) {
df %>%
mutate(
sales_price_BTC = sales_price_mnok / NOKBTC,
mNOK_val_sales =
lead(NOKBTC, lead_days, order_by = date)
* sales_price_BTC,
profit_mnok = mNOK_val_sales - car_cost_mnok
)
}
initial_equity <- 10
test_neg_equity <-
function(df, startdate, lead_days) {
tmpdf <-
df %>%
filter(date >= startdate) %>%
calcProfits(sales_price_mnok, car_cost_mnok, lead_days) %>%
filter(complete.cases(.))
if (nrow(tmpdf) > 0) {
tmpdf %>%
mutate(cumulative_profits_mnok = cumsum(profit_mnok)) %>%
summarise(negative_equity =
1 * (min(
cumulative_profits_mnok + initial_equity
) < 0)) %>%
pull %>%
return
} else{
return(NA_real_)
}
}
# Lets use some funcionality for storing how low time it takes to complete the calculation
library(tictoc)
# Lets use some funcionality for storing how low time it takes to complete the calculation
install.packages(tictoc)
# Lets use some funcionality for storing how low time it takes to complete the calculation
install.packages("tictoc")
library(tictoc)
tic()
Sys.sleep(1)
toc()
printTicTocLog <-
function() {
tic.log() %>%
unlist %>%
tibble(logvals = .) %>%
separate(logvals,
sep = ":",
into = c("Function type", "log")) %>%
mutate(log = str_trim(log)) %>%
separate(log,
sep = " ",
into = c("Seconds"),
extra = "drop")
}
tic.clearlog()
tic("Test")
Sys.sleep(1)
toc(log = TRUE)
View(printTicTocLog)
View(test_neg_equity)
printTicTocLog() %>%
knitr::kable()
df_results <-
expand.grid(date = df$date,
lead_days = c(1, 5, 10, 30, 60)) %>%
mutate(neg_eq = NA) %>%
as_tibble()
tic.clearlog()
tic("Regular loop")
for (i in 1:nrow(df_results)) {
df_results$neg_eq[i] <-
test_neg_equity(df,
startdate = df_results$date[i],
lead_days = df_results$lead_days[i])
}
toc(log = TRUE)
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
for(i in 1:nrow(df_results)) {
df_results$neg_eq[i] <-
test_neg_equity(df,
startdate = df_results$date[i],
lead_days = df_results$lead_days[i])
}
# 9.5 Using multiple cores in R ------------------------------------------------
install.packages("doParallel")
library(doParallel)
maxcores <- 8
Cores <- min(parallel::detectCores(), maxcores)
cl <- makeCluster(Cores)
View(cl)
View(cl)
registerDoParallel(cl)
cl <- makeCluster(Cores)
registerDoParallel(cl)
tic(paste0("Parallel loop, ", Cores, " cores"))
res <-
foreach(
i = 1:nrow(df_results),
.combine = 'rbind',
.packages = c('magrittr', 'dplyr')
) %dopar%
tibble(
date = df_results$date[i],
lead_days = df_results$lead_days[i],
neg_eq =
test_neg_equity(
df,
startdate = df_results$date[i],
lead_days = df_results$lead_days[i]
)
)
stopCluster(cl)
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
library(purrr)
tic("purrr")
df_results$neg_eq <-
df %>%
map2_dbl(as.list(df_results$date),
as.list(df_results$lead_days),
test_neg_equity,
df = .)
toc(log = TRUE)
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
library(furrr)
plan(multisession, workers = Cores)
tic(paste0("furrr, ", Cores, " cores"))
df_results$neg_eq <-
df %>%
future_map2_dbl(as.list(df_results$date),
as.list(df_results$lead_days),
test_neg_equity,
df = .)
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
maxcores <- 12
for (Cores in 1:maxcores) {
plan(multisession, workers = Cores)
tic(paste0("furrr, ", Cores, " cores"))
df_results$neg_eq <-
df %>%
future_map2_dbl(as.list(df_results$date),
as.list(df_results$lead_days),
test_neg_equity,
df = .)
toc(log = TRUE)
}
maxcores <- 16
for (Cores in 1:maxcores) {
plan(multisession, workers = Cores)
tic(paste0("furrr, ", Cores, " cores"))
df_results$neg_eq <-
df %>%
future_map2_dbl(as.list(df_results$date),
as.list(df_results$lead_days),
test_neg_equity,
df = .)
toc(log = TRUE)
}
printTicTocLog() %>%
tail(maxcores) %>%
separate(
`Function type`,
sep = " ",
into = c("Function type", "nCores"),
extra = "drop"
) %>%
mutate(
Seconds = as.numeric(Seconds),
nCores = as.numeric(nCores),
lowered_compute_time = Seconds / lag(Seconds, order_by = nCores) - 1,
theoretical_max = lag(nCores) / nCores - 1
) %>%
ggplot(aes(x = nCores)) +
geom_line(aes(y = lowered_compute_time, col = "Realized performance gain")) +
geom_line(aes(y = theoretical_max, col = "Theoretical performance gain")) +
theme_classic() +
xlab("Number of cores") +
ylab("Lowered compute time by additional core") +
theme(legend.title = element_blank(),
legend.position = 'bottom')
setwd("/Users/susannaroald/Documents/git_assignment_pc/parallel-computing-Susanna-R")
